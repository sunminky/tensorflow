{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12 다중머신과 장치를 위한 분산 텐서플로 ##\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 24 20:04:14 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 451.67       Driver Version: 451.67       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106... WDDM  | 00000000:06:00.0  On |                  N/A |\n",
      "|  0%   29C    P5    14W / 120W |    514MiB /  3072MiB |      9%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1348    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      5660    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      8240    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8916    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9268    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     11296    C+G   ...3.0.8.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     12080    C+G   ...llpaper\\pushwallpaper.exe    N/A      |\n",
      "|    0   N/A  N/A     12104    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     13756    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     14204    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주의할 점은, 이 옵션은 메모리의 증식만 가능하다는 것. 연산이 끝나고 메모리가 필요없는 상황이라고 해서 할당된 메모리를 반납하지 않는다. \\n\\nTensorflow 측에서는 그럴 경우 더 심한 메모리 파편화를 일으킬 수도 있다고 하니 판단은 독자의 몫.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GPU 메모리 관리 ##\n",
    "#1번 방법\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True #메모리 수요에 따라 할당\n",
    "\n",
    "'''주의할 점은, 이 옵션은 메모리의 증식만 가능하다는 것. 연산이 끝나고 메모리가 필요없는 상황이라고 해서 할당된 메모리를 반납하지 않는다. \n",
    "\n",
    "Tensorflow 측에서는 그럴 경우 더 심한 메모리 파편화를 일으킬 수도 있다고 하니 판단은 독자의 몫.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU 메모리 관리 ##\n",
    "#2번 방법\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3 #메모리 할당 비율 설정\n",
    "#config.gpu_options.allow_growth = True #메모리 수요에 따라 할당, 두개 같이 사용 가능(추천하지는 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.log_device_placement = True #배치자가 노드를 배치할 때마다 메세지 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device(\"/cpu:0\"): #변수 a와 b를 cpu에 할당\n",
    "    a = tf.Variable(3.0)\n",
    "    b = tf.Variable(4.0)\n",
    "    \n",
    "c = a * b #c는 어떤 장치에도 할당되지 않았으므로 기본장치에 배치됨\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "## 동적배치함수 ##\n",
    "def variables_on_cpu(op): #연산이 할당될 장치이름 반환\n",
    "    if op.type == \"Variable\":\n",
    "        return \"/cpu:0\"\n",
    "    else:\n",
    "        return \"/gpu:0\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device(variables_on_cpu):\n",
    "    a = tf.Variable(3.0) #타입이 Variable이므로 cpu에 할당됨\n",
    "    b = tf.Variable(4.0) #타입이 Variable이므로 cpu에 할당됨\n",
    "    #b = tf.Variable(4) #gpu에는 int32형 변수 할당불가능\n",
    "    c = a * b \n",
    "    \n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 간접배치 ##\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config.allow_soft_placement = True #처리할 커널이 없는 장치에 할당했을 때 cpu로 처리할수 있도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    b = tf.Variable(4) #cpu에 할당될 것임\n",
    "    \n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "## 제어의존성 ##\n",
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = a + 2.0\n",
    "\n",
    "with tf.control_dependencies([a, b]): #a,b가 평가된 두 x, y가 평가되게 함\n",
    "    x = tf.constant(3.0)\n",
    "    y = tf.constant(4.0)\n",
    "\n",
    "z = x * y * b\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n클러스터 : 1개 이상의 태스크, 보통 여러 머신에 나뉘어 있음\\n태스크 : 하나의 잡에 속함, 하나의 잡은 이름이 부여된 태스크의 그룹(워커 / 파라미터 서버)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.2. 다중 머신의 다중 장치 ##\n",
    "'''\n",
    "클러스터 : 1개 이상의 태스크, 보통 여러 머신에 나뉘어 있음\n",
    "태스크 : 하나의 잡에 속함, 하나의 잡은 이름이 부여된 태스크의 그룹(워커 / 파라미터 서버)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>로컬 서버</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello distributed TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(\"Hello distributed TensorFlow!\")\n",
    "server = tf.train.Server.create_local_server() #in-process 서버 형태로 단일 프로세스 클러스터를 생성\n",
    "with tf.Session(server.target) as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>클러스터</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#클러스터 명세\n",
    "\n",
    "cluster_spec = tf.train.ClusterSpec({\n",
    "    \"ps\":[\n",
    "        \"127.0.0.1:2221\",  # /job:ps/task:0\n",
    "        \"127.0.0.1:2222\",  # /job:ps/task:1\n",
    "    ],\n",
    "    \"worker\":[\n",
    "        \"127.0.0.1:2223\",  # /job:worker/task:0\n",
    "        \"127.0.0.1:2224\",  # /job:worker/task:1\n",
    "        \"127.0.0.1:2225\",  # /job:worker/task:2\n",
    "    ]})\n",
    "\n",
    "# $ CUDA_VISIBLE_DEVICES=\"\" python my_script.py # CPU만 사용하겠다는 뜻(파라미터 서버 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ps0 = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=0) #첫번째 \"ps\" 태스크를 시작\n",
    "task_ps1 = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=1) #두번째 \"ps\" 태스크를 시작\n",
    "task_worker0 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0) #첫번째 \"worker\" 태스크를 시작\n",
    "task_worker1 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=1) #두번째 \"worker\" 태스크를 시작\n",
    "task_worker2 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=2) #세번째 \"worker\" 태스크를 시작\n",
    "\n",
    "#server.join() #만약 서버를 실행하기만 하는 프로세스라면 다른서버가 종료될 때 까지 서버가 종료되지 않게 해야 함,\n",
    "#실제로는 서버를 중지시키는 방법은 없기때문에 영원히 블록됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>장치와 서버간 파이프라이닝</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device(\"/job:ps\"): #ps잡의 1번째 태스크의 기본장치(cpu0)에 할당됨\n",
    "    a = tf.Variable(1.0, name=\"a\")\n",
    "\n",
    "with tf.device(\"/job:worker/task:0\"): #worker잡의 1번째 태스크의 기본장치(gpu0)에 할당됨\n",
    "    b = a + 2\n",
    "    \n",
    "with tf.device(\"/job:worker/task:1/gpu:0\"): #worker잡의 2번째 태스크의 1번째 gpu에 할당됨\n",
    "    c = a + b\n",
    "    \n",
    "d = c * 2 #자신의 기본 장치에 할당됨\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2221\") as sess:\n",
    "    sess.run(a.initializer)\n",
    "    print(d.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device(tf.train.replica_device_setter( #라운드로빈 방식으로 변수들을 각 서버에 분산시킴\n",
    "        ps_tasks=2, #ps태스크의 수, cluster=cluster_spec를 지정해서 ps잡에 있는 태스크의 수를 찾게 할수도 있음\n",
    "        ps_device=\"/job:ps\", #파마리터 서버 태스크 지정\n",
    "        worker_device=\"/job:worker\")): #워커 잡의 장치 지정\n",
    "    v1 = tf.Variable(1.0, name=\"v1\")  # pinned to /job:ps/task:0 (defaults to /cpu:0)\n",
    "    v2 = tf.Variable(2.0, name=\"v2\")  # pinned to /job:ps/task:1 (defaults to /cpu:0)\n",
    "    v3 = tf.Variable(3.0, name=\"v3\")  # pinned to /job:ps/task:0 (defaults to /cpu:0)\n",
    "    s = v1 + v2            # pinned to /job:worker (defaults to task:0/cpu:0)\n",
    "    with tf.device(\"/task:1\"):\n",
    "        p1 = 2 * s         # pinned to /job:worker/task:1 (defaults to /cpu:0)\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            p2 = 3 * s     # pinned to /job:worker/task:1/cpu:0\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2221\", config=config) as sess:\n",
    "    sess.run([v1.initializer, v2.initializer, v3.initializer])\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\", config=config) as sess:\n",
    "    print(sess.run(p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 리소스 컨테이너를 사용해 여러 세션에서 상태 공유하기 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "x = tf.Variable(0.0, name=\"x\") #같은 클러스터에 있는 다른 세션에서 사용 가능\n",
    "increment_x = tf.assign(x, x+1)\n",
    "\n",
    "#init\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess:\n",
    "    sess.run(x.initializer)\n",
    "    sess.run(increment_x)\n",
    "    print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#다른 세션에서 같은 클러스터에 있는 변수 사용\n",
    "with tf.Session(\"grpc://127.0.0.1:2224\") as sess:\n",
    "    sess.run(increment_x)\n",
    "    print(x.eval())\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2225\") as sess:\n",
    "    sess.run(increment_x)\n",
    "    print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#컨테이너 사용\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#init\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess:\n",
    "    x_share = tf.Variable(1.0, name=\"x_share\")\n",
    "    increment_x_share = tf.assign(x_share, x_share+1)\n",
    "    with tf.container(\"myProblem\"):\n",
    "        x = tf.Variable(10.0, name=\"x\") #같은 클러스터에 있는 다른 세션에서 사용 가능\n",
    "        increment_x = tf.assign(x, x+1)\n",
    "    \n",
    "    sess.run(x.initializer)\n",
    "    sess.run(increment_x)\n",
    "    print(x.eval())\n",
    "    \n",
    "    ###같은 클러스터 내에서 공유 가능한 변수###\n",
    "    sess.run(x_share.initializer)\n",
    "    sess.run(increment_x_share)\n",
    "    print(x_share.eval())\n",
    "    \n",
    "tf.Session.reset(\"grpc://127.0.0.1:2223\", [\"myProblem\"]) #myProblem 이름을 가진 컨테이너 리셋(컨테이너가 사용하는 모든 리소스 해제)\n",
    "      \n",
    "with tf.Session(\"grpc://127.0.0.1:2224\") as sess:\n",
    "    #sess.run(increment_x) #접근 불가능, 리소스  해제 됨\n",
    "    \n",
    "    ###같은 클러스터 내에서 공유 가능한 변수###\n",
    "    sess.run(increment_x_share)\n",
    "    print(x_share.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>텐서플로 큐를 사용한 비동기 통신</h2>\n",
    "\n",
    "![텐서플로우 큐](img/queue.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더\n",
    "\n",
    "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name=\"q\", shared_name=\"shared_q\") #FIRO 큐 생성\n",
    "#큐가 공유하기 위해서 shared_name을 사용, 물론 같은 컨테이너를 사용해야함\n",
    "training_instance = tf.placeholder(tf.float32, shape=(2)) #데이터가 담길 변수\n",
    "enqueue = q.enqueue([training_instance]) #큐에 데이터 집어넣음\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess:\n",
    "    sess.run(enqueue, feed_dict={training_instance: [1., 2.]}) #큐에 데이터 집어넣음\n",
    "    sess.run(enqueue, feed_dict={training_instance: [3., 4.]}) #큐에 데이터 집어넣음\n",
    "    sess.run(enqueue, feed_dict={training_instance: [5., 6.]}) #큐에 데이터 집어넣음\n",
    "    #sess.run(q.close()) #더 이상 데이터가 추가되지 않을 큐를 종료\n",
    "    #sess.run(q.close(cancel_pending_enqueues=True)) #대기 중인 enqueue 요청 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위와 동일\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name=\"q\", shared_name=\"shared_q\") #FIRO 큐 생성\n",
    "training_instances = tf.placeholder(tf.float32, shape=(None, 2)) #데이터가 담길 변수\n",
    "enqueue = q.enqueue_many([training_instances]) #큐에 데이터를 한번에 많이 집어넣음\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess:\n",
    "    sess.run(enqueue, feed_dict={training_instances: [[1., 2.], [3., 4.], [5., 6.]]}) #큐에 데이터를 한번에 많이 집어넣음\n",
    "    sess.run(q.close()) #더 이상 데이터가 추가되지 않을 큐를 종료\n",
    "    #sess.run(q.close(cancel_pending_enqueues=True)) #대기 중인 enqueue 요청 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "[3. 4.]\n",
      "[5. 6.]\n"
     ]
    }
   ],
   "source": [
    "#데이터 추출\n",
    "\n",
    "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name=\"q\", shared_name=\"shared_q\") #FIRO 큐 생성\n",
    "dequeue_mini_batch = q.dequeue() #큐에서 데이터 뽑음\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2224\") as sess:\n",
    "    print(sess.run(dequeue_mini_batch))\n",
    "    print(sess.run(dequeue_mini_batch))\n",
    "    print(sess.run(dequeue_mini_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[[5. 6.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n큐가 꽉차면 enqueue 연산은 dequeue 연산으로 큐에 남는 자리가 생길 때 까지 대기\\n큐가 비어있거나 dequeue_many 의 미니배치 사이즈보다 큐에 있는 아이템의 수가 적으면 enqueue 연산으로 데이터 들어올 때 까지 대기\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위와 동일\n",
    "\n",
    "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[[2]], name=\"q\", shared_name=\"shared_q\") #FIRO 큐 생성\n",
    "batch_size = 2\n",
    "#dequeue_mini_batch = q.dequeue_many(batch_size) #큐에서 배치사이즈 만큼 데이터 뽑음, 데이터가 모자라면 다른 샘플이 올 때 까지 대기\n",
    "dequeue_mini_batch = q.dequeue_up_to(batch_size) #큐에서 배치사이즈 만큼 데이터 뽑음, 데이터가 모자라면 나머지라도 긁어서 옴\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2224\") as sess:\n",
    "    print(sess.run(dequeue_mini_batch))\n",
    "    print(sess.run(dequeue_mini_batch))\n",
    "\n",
    "'''\n",
    "큐가 꽉차면 enqueue 연산은 dequeue 연산으로 큐에 남는 자리가 생길 때 까지 대기\n",
    "큐가 비어있거나 dequeue_many 의 미니배치 사이즈보다 큐에 있는 아이템의 수가 적으면 enqueue 연산으로 데이터 들어올 때 까지 대기\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#튜플 큐 (큐에 있는 아이템이 하나의 텐서 대신 텐서의 튜플)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tq = tf.FIFOQueue(capacity=10, dtypes=[tf.int32, tf.float32], shapes=[[], [3, 2]],\n",
    "                 name=\"tq\", shared_name=\"shaed_tq\")\n",
    "\n",
    "a = tf.placeholder(tf.int32, shape=())\n",
    "b = tf.placeholder(tf.float32, shape=(3, 2))\n",
    "enqueue = tq.enqueue((a, b))\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2224\") as sess:\n",
    "    sess.run(enqueue, feed_dict={a: 10, b: [[1., 2.], [3., 4.], [5., 6.]]})\n",
    "    sess.run(enqueue, feed_dict={a: 20, b: [[21., 22.], [23., 24.], [25., 26.]]})\n",
    "    sess.run(enqueue, feed_dict={a: 30, b: [[31., 32.], [33., 34.], [35., 36.]]})\n",
    "    sess.run(tq.close())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "t_dequeue_a, t_dequeue_b = tq.dequeue()\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess:\n",
    "    a_val, b_val = sess.run([t_dequeue_a, t_dequeue_b])\n",
    "    print(a_val)\n",
    "    print(b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 30]\n",
      "[[[21. 22.]\n",
      "  [23. 24.]\n",
      "  [25. 26.]]\n",
      "\n",
      " [[31. 32.]\n",
      "  [33. 34.]\n",
      "  [35. 36.]]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "t_dequeue_as, t_dequeue_bs = tq.dequeue_up_to(batch_size)\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2223\") as sess:\n",
    "    a_val, b_val = sess.run([t_dequeue_as, t_dequeue_bs])\n",
    "    print(a_val)\n",
    "    print(b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아이템을 랜덤하게 변환하여 반환하는 큐\n",
    "r_q = tf.RandomShuffleQueue(capacity=50, min_after_dequeue=10, #큐에 남아있어야 하는 최소 아이템의 수 10개\n",
    "                           dtypes=[tf.float32], shapes=[()],\n",
    "                           name=\"r_q\", shared_name=\"shared_r_q\")\n",
    "\n",
    "#크기가 다른 텐서를 받는 큐\n",
    "p_q = tf.PaddingFIFOQueue(capacity=50, dtypes=[tf.float32],\n",
    "                         shapes=[(None, None)], name=\"r_q\",\n",
    "                         shared_name=\"shared_r_q\")\n",
    "v = tf.placeholder(tf.float32, shape=(None, None))\n",
    "p_enqueue = p_q.enqueue([v])\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2222\") as sess:\n",
    "    sess.run(p_enqueue, feed_dict={v: [[1., 2.], [3., 4.], [5., 6.]]}) #3*2 텐서\n",
    "    sess.run(p_enqueue, feed_dict={v: [[1., 2., 3., 4.], [5., 6., 7., 8.]]}) #2*4 텐서\n",
    "    sess.run(p_enqueue, feed_dict={v: [[1., 2.], [3., 4.], [5., 6.], [7., 8.], [9., 10.]]}) #5*2 텐서\n",
    "    sess.run(p_q.close())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsonml",
   "language": "python",
   "name": "handsonml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
