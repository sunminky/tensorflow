{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전형적인 CNN구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![구조](./images/전형적인구조.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>입력</li>\n",
    "    <li>합성곱</li>\n",
    "    <li>풀링</li>\n",
    "    <li>합성곱</li>\n",
    "    <li>풀링</li>\n",
    "    <li>완전연결</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "\n",
    "합성곱에 3X3 커널 두개를 이어서 9X9 커널과 같은 효과를 낼수 있음\n",
    "<p>3X3 커널 두개를 합친것이 9X9 커널 하나보다 파라미터와 계산량이 적음</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "\n",
    "![기본컨볼루션](./images/기본컨볼루션.gif)\n",
    "<center><b>2D convolution using a kernel size of 3, stride of 1 and padding</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>Kernel Size</b> : kernel size는 convolution의 시야(view)를 결정합니다. 보통 2D에서 3x3 pixel로 사용합니다</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>Stride</b> : stride는 이미지를 횡단할 때 커널의 스텝 사이즈를 결정합니다. 기본값은 1이지만 보통 Max Pooling과 비슷하게 이미지를 다운샘플링하기 위해 Stride를 2로 사용할 수 있습니다.</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>Padding</b> : Padding은 샘플 테두리를 어떻게 조절할지를 결정합니다. 패딩된 Convolution은 input과 동일한 output 차원을 유지하는 반면, 패딩되지 않은 Convolution은 커널이 1보다 큰 경우 테두리의 일부를 잘라버릴 수 있습니다.</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>Input & Output Channels</b> : Convolution layer는 Input 채널의 특정 수(I)를 받아 output 채널의 특정 수(O)로 계산합니다. 이런 계층에서 필요한 파라미터의 수는 I*O*K로 계산할 수 있습니다. K는 커널의 수입니다.</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>tf.layers.conv1d()</b> : 1D 입력에 대한 합성곱층 생성</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>tf.layers.conv3d()</b> : 3D 입력에 대한 합성곱층 생성</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atrous convolutions\n",
    "\n",
    "![아트루스](./images/아트루스.gif)\n",
    "<center><b>2D convolution using a 3 kernel with a dilation rate of 2 and no padding</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">0으로 된 행과 열을 추가하여 늘린 필터로 보통의 합성곱층을 사용하는 것과 동일</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">입력을 건너뛰면서 합성곱을 하는 것과 같음</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">[[1, 2,3 ]]과 같은 1X3 필터를 팽창비율 4로 늘리면 팽창된 필터는 [[1, 0, 0, 0, 2, 0, 0, 0, 3]]이 됨</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">추가적인 계산비용이나 파라미터를 발생시키지 않고 더 큰 수용장을 가지는 합성곱층으 만듬</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>tf.nn.atrous_conv2d()</b> : 아트루스 합성곱층 생성</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposed Convolutions\n",
    "\n",
    "![전치합성곱2](./images/전치합성곱2.gif)\n",
    "<center><b>Transposed 2D convolution with no padding, stride of 2 and kernel of 3</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">convolution의 과정을 되돌립니다. 하나의 convolutional layer에 이미지를 입력한다고 상상해보겠습니다. 이제 출력물을 가져와 블랙 박스에 넣으면 원본 이미지가 다시 나타납니다.</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">입력값 사이에 0을 추가하는 것과 같음</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">전형적인 CNN에서 네트워크를 통과할수록 특성맵이 작아지기때문에 입력과 같은 크기의 출력을 만들기위해 업샘플링 층이 필요함</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>tf.layers.conv2d_transpose()</b> : 이미지를 업샘플링하여 전치 합성곱층 생성</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depthwise Convolutions\n",
    "\n",
    "![깊이방향합성곱](./images/깊이방향합성곱.png)\n",
    "<center><b>apply a single convolutional filter for each input channel</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">모든 필터가 모든 개개의 입력 채널에 독립적으로 적용됨</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>특성맵의 수</b> : (필터의 수) X (입력데이터 채널의 수)</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>tf.nn.depthwise_conv2d()</b> : 깊이방향 합성곱층 생성</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separable Convolutions\n",
    "\n",
    "![분리형합성곱](./images/분리형합성곱.png)\n",
    "<center><b>3X3 커널 하나 사용(파라미터 9개) vs 1X3, 3X1 커널 사용(파라미터 6개)</b></center>\n",
    "\n",
    "![깊이방향분리형합성곱](./images/깊이방향분리형합성곱.jpg)\n",
    "<center><b>깊이 방향 합성곱층 적용 후 1X1 합성곱층을 사용해 특성맵을 추출</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">컬러이미지를 다루는 합성곱 네트워크 시작 부분에서 파라미터 수를 줄이기 위해 사용됨</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">처음에는 깊이 방향 합성곱층처럼 작용하고 그 다음에는 1X1 합성곱층을 적용해 특성맵을 출력</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">입력채널은 depthwise_filter 매개변수의 마지막 차원인 channel_mutiplier만큼 증폭되고 다시 pointwise_filter 매개변수의 마지막 차원인 out_channels만큼 1X1합성곱으로 출력이 만들어 짐</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\">5X5 커널로 RGB 3개 채널을 합성곱하여 10개의 출력을 만들때, 원래는 5 * 5 * 3 * 10 = 750개의 파라미터가 필요하지만 channel_multiplier를 4로 한 seperable_conv2d를 사용하면 5 * 5 * 3 * 4 + 1 * 1 * (3 * 4) * 10 = 420 개의 파라미터 사용</li>\n",
    "    <li style=\"font-size:1.3em; margin: 0.3em 0\"><b>tf.layers.seperable_conv2d()</b> : 분리형 합성곱층 생성</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsonmlcpu",
   "language": "python",
   "name": "handsonmlcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
